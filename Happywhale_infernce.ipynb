{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1102cd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:01.906418Z",
     "iopub.status.busy": "2022-02-23T05:09:01.905463Z",
     "iopub.status.idle": "2022-02-23T05:09:06.476687Z",
     "shell.execute_reply": "2022-02-23T05:09:06.477439Z",
     "shell.execute_reply.started": "2022-02-23T04:59:51.916818Z"
    },
    "papermill": {
     "duration": 4.663889,
     "end_time": "2022-02-23T05:09:06.477648",
     "exception": false,
     "start_time": "2022-02-23T05:09:01.813759",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import cv2\n",
    "import math\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "# For data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Pytorch Imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "\n",
    "# Utils\n",
    "import joblib\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Sklearn Imports\n",
    "from sklearn.preprocessing import LabelEncoder, normalize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# For Image Models\n",
    "import timm\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006ada57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:06.853204Z",
     "iopub.status.busy": "2022-02-23T05:09:06.852356Z",
     "iopub.status.idle": "2022-02-23T05:09:06.855417Z",
     "shell.execute_reply": "2022-02-23T05:09:06.855011Z",
     "shell.execute_reply.started": "2022-02-23T04:59:56.735856Z"
    },
    "papermill": {
     "duration": 0.135189,
     "end_time": "2022-02-23T05:09:06.855536",
     "exception": false,
     "start_time": "2022-02-23T05:09:06.720347",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIG = {\"seed\": 42, # 随机种子\n",
    "          \"img_size\": 768, # 图像尺寸\n",
    "          \"model_name\": \"tf_efficientnet_b6_ns\", # 模型名称 tf_efficientnet_b6_ns, tf_efficientnetv2_l_in21k, eca_nfnet_l2 \n",
    "          \"num_classes\": 15587, # 类别数量\n",
    "          \"embedding_size\": 512, # embedding 维度\n",
    "          \"train_batch_size\": 64, # 训练 batch size\n",
    "          \"valid_batch_size\": 64, # 验证 batch size\n",
    "          \"n_fold\": 5, # fold\n",
    "          \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"), # gpu / cpu\n",
    "          \"gpu_parallel\":True, # 并行gpu\n",
    "          \"image_data\":\"fullbody\", # 数据路径 backfins, fullbody \n",
    "          \"debug\":True, # debug 模式\n",
    "          \"num_workers\":10, # cpu线程数\n",
    "\n",
    "          # ArcFace Hyperparameters\n",
    "          \"s\": 30.0, # arcface scale\n",
    "          \"m\": 0.30, # arcface margin\n",
    "          \"ls_eps\": 0.0, # arcface label smoothing\n",
    "          \"easy_margin\": False, # arcface easy_margin\n",
    "\n",
    "          # KNN\n",
    "          \"KNN\":850,\n",
    "          \n",
    "          }\n",
    "\n",
    "# 调试模式参数\n",
    "if CONFIG[\"debug\"]:\n",
    "    CONFIG[\"img_size\"] = 512\n",
    "    CONFIG[\"model_name\"] = \"tf_efficientnet_b0_ns\"\n",
    "    CONFIG[\"train_batch_size\"] = 32\n",
    "    CONFIG[\"valid_batch_size\"] = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cfc6f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:07.190017Z",
     "iopub.status.busy": "2022-02-23T05:09:07.189339Z",
     "iopub.status.idle": "2022-02-23T05:09:07.197816Z",
     "shell.execute_reply": "2022-02-23T05:09:07.197367Z",
     "shell.execute_reply.started": "2022-02-23T04:59:56.790906Z"
    },
    "papermill": {
     "duration": 0.095411,
     "end_time": "2022-02-23T05:09:07.197943",
     "exception": false,
     "start_time": "2022-02-23T05:09:07.102532",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    '''\n",
    "    随机种子\n",
    "    '''\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False # set True to be faster\n",
    "seed_everything(CONFIG['seed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e57e0e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:07.364310Z",
     "iopub.status.busy": "2022-02-23T05:09:07.363433Z",
     "iopub.status.idle": "2022-02-23T05:09:07.365261Z",
     "shell.execute_reply": "2022-02-23T05:09:07.365693Z",
     "shell.execute_reply.started": "2022-02-23T04:59:56.806296Z"
    },
    "papermill": {
     "duration": 0.087356,
     "end_time": "2022-02-23T05:09:07.365844",
     "exception": false,
     "start_time": "2022-02-23T05:09:07.278488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BASE_DIR = './'\n",
    "ROOT_DIR = './'\n",
    "\n",
    "if CONFIG[\"image_data\"] == \"backfins\":\n",
    "    # backfins 数据\n",
    "    TRAIN_DIR = f'{ROOT_DIR}/train_backfins_images'\n",
    "    TEST_DIR = f'{ROOT_DIR}/test_backfins_images'\n",
    "elif CONFIG[\"image_data\"] == \"fullbody\":\n",
    "    # fullbody 数据\n",
    "    TRAIN_DIR = f'{ROOT_DIR}/train_fullbody_images'\n",
    "    TEST_DIR = f'{ROOT_DIR}/test_fullbody_images'\n",
    "else:\n",
    "    # 完整版数据\n",
    "    TRAIN_DIR = f'{ROOT_DIR}/train_images'\n",
    "    TEST_DIR = f'{ROOT_DIR}/test_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cce397f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:07.859225Z",
     "iopub.status.busy": "2022-02-23T05:09:07.858351Z",
     "iopub.status.idle": "2022-02-23T05:09:07.985429Z",
     "shell.execute_reply": "2022-02-23T05:09:07.985895Z",
     "shell.execute_reply.started": "2022-02-23T04:59:56.824790Z"
    },
    "papermill": {
     "duration": 0.212231,
     "end_time": "2022-02-23T05:09:07.986051",
     "exception": false,
     "start_time": "2022-02-23T05:09:07.773820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 读取train csv文件\n",
    "def get_train_file_path(id):\n",
    "    return f\"{TRAIN_DIR}/{id}\"\n",
    "\n",
    "df = pd.read_csv(f\"{ROOT_DIR}/train.csv\")\n",
    "df['file_path'] = df['image'].apply(get_train_file_path) # 加上图像路径\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f583ffdb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:08.165948Z",
     "iopub.status.busy": "2022-02-23T05:09:08.165175Z",
     "iopub.status.idle": "2022-02-23T05:09:08.201980Z",
     "shell.execute_reply": "2022-02-23T05:09:08.201445Z",
     "shell.execute_reply.started": "2022-02-23T04:59:56.939790Z"
    },
    "papermill": {
     "duration": 0.135918,
     "end_time": "2022-02-23T05:09:08.202120",
     "exception": false,
     "start_time": "2022-02-23T05:09:08.066202",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 对label做 标签编码\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# with open(f'{ROOT_DIR}/le.pkl', \"rb\") as fp:\n",
    "#     encoder = joblib.load(fp)\n",
    "\n",
    "# df['individual_id'] = encoder.transform(df['individual_id'])\n",
    "df['individual_id'] = encoder.fit_transform(df['individual_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544990c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:08.370561Z",
     "iopub.status.busy": "2022-02-23T05:09:08.369695Z",
     "iopub.status.idle": "2022-02-23T05:09:08.837347Z",
     "shell.execute_reply": "2022-02-23T05:09:08.836746Z",
     "shell.execute_reply.started": "2022-02-23T04:59:56.973632Z"
    },
    "papermill": {
     "duration": 0.554876,
     "end_time": "2022-02-23T05:09:08.837477",
     "exception": false,
     "start_time": "2022-02-23T05:09:08.282601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 分层KFold\n",
    "skf = StratifiedKFold(n_splits=CONFIG['n_fold'])\n",
    "for fold, ( _, val_) in enumerate(skf.split(X=df, y=df.individual_id)):\n",
    "      df.loc[val_ , \"kfold\"] = fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f516bd05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:09.172469Z",
     "iopub.status.busy": "2022-02-23T05:09:09.170894Z",
     "iopub.status.idle": "2022-02-23T05:09:09.173063Z",
     "shell.execute_reply": "2022-02-23T05:09:09.173464Z",
     "shell.execute_reply.started": "2022-02-23T04:59:57.432756Z"
    },
    "papermill": {
     "duration": 0.091753,
     "end_time": "2022-02-23T05:09:09.173623",
     "exception": false,
     "start_time": "2022-02-23T05:09:09.081870",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HappyWhaleDataset(Dataset):\n",
    "    '''\n",
    "    torch HappyWhale DataSets\n",
    "    '''\n",
    "    def __init__(self, df, transforms=None):\n",
    "        self.df = df # csv to dataframe\n",
    "        self.ids = df['image'].values # 获取image filename\n",
    "        self.file_names = df['file_path'].values # 获取图像路径\n",
    "        self.labels = df['individual_id'].values # 获取labels\n",
    "        self.transforms = transforms # 数据增强\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df) # 数据集长度\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        idx = self.ids[index]  # 获取某张图片 filename\n",
    "        img_path = self.file_names[index] # 获取某张图片的路径\n",
    "        img = cv2.imread(img_path) # 读取图片\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR to RGB\n",
    "        label = self.labels[index] # 获取labels\n",
    "        \n",
    "        if self.transforms:\n",
    "            img = self.transforms(image=img)[\"image\"] # 对图像应用数据增强\n",
    "            \n",
    "        return {\n",
    "            'image': img, # 返回图像\n",
    "            'label': torch.tensor(label, dtype=torch.long), # 返回labels\n",
    "            'id': idx # 返回filename\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab578f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:09.505849Z",
     "iopub.status.busy": "2022-02-23T05:09:09.504905Z",
     "iopub.status.idle": "2022-02-23T05:09:09.506666Z",
     "shell.execute_reply": "2022-02-23T05:09:09.507167Z",
     "shell.execute_reply.started": "2022-02-23T04:59:57.442363Z"
    },
    "papermill": {
     "duration": 0.090063,
     "end_time": "2022-02-23T05:09:09.507329",
     "exception": false,
     "start_time": "2022-02-23T05:09:09.417266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据增强\n",
    "data_transforms = {\n",
    "    \"train\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),  # Resize\n",
    "        # 归一化\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.),\n",
    "    \n",
    "    \"valid\": A.Compose([\n",
    "        A.Resize(CONFIG['img_size'], CONFIG['img_size']),  # Resize\n",
    "        # 归一化\n",
    "        A.Normalize(\n",
    "                mean=[0.485, 0.456, 0.406], \n",
    "                std=[0.229, 0.224, 0.225], \n",
    "                max_pixel_value=255.0, \n",
    "                p=1.0\n",
    "            ),\n",
    "        ToTensorV2()], p=1.)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1a59b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GeM Pooling 详解可查看讲义\n",
    "class GeM(nn.Module):\n",
    "    def __init__(self, p=3, eps=1e-6):\n",
    "        super(GeM, self).__init__()\n",
    "        self.p = nn.Parameter(torch.ones(1)*p) # 比例p参数\n",
    "        self.eps = eps  # eps 防止除零\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.gem(x, p=self.p, eps=self.eps)\n",
    "        \n",
    "    def gem(self, x, p=3, eps=1e-6):\n",
    "        return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + \\\n",
    "                '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + \\\n",
    "                ', ' + 'eps=' + str(self.eps) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23165d1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:10.179824Z",
     "iopub.status.busy": "2022-02-23T05:09:10.178836Z",
     "iopub.status.idle": "2022-02-23T05:09:10.181012Z",
     "shell.execute_reply": "2022-02-23T05:09:10.181388Z",
     "shell.execute_reply.started": "2022-02-23T04:59:57.466699Z"
    },
    "papermill": {
     "duration": 0.096308,
     "end_time": "2022-02-23T05:09:10.181535",
     "exception": false,
     "start_time": "2022-02-23T05:09:10.085227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Arcface\n",
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, \n",
    "                 m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features  # input的维度\n",
    "        self.out_features = out_features # output的维度\n",
    "        self.s = s # re-scale\n",
    "        self.m = m # margin\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        # 初始化权重\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin # easy_margin 模式\n",
    "        self.cos_m = math.cos(m) # cos margin\n",
    "        self.sin_m = math.sin(m) # sin margin\n",
    "        self.threshold = math.cos(math.pi - m) # cos(pi - m) = -cos(m)\n",
    "        self.mm = math.sin(math.pi - m) * m # sin(pi - m)*m = sin(m)*m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight)) # 获得cosθ (vector)\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2)) # 获得cosθ\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m # cosθ*cosm – sinθ*sinm = cos(θ + m)\n",
    "        phi = phi.float() # phi to float\n",
    "        cosine = cosine.float() # cosine to float\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            # 以下代码控制了 θ+m 应该在 range[0, pi]\n",
    "            # if cos(θ) > cos(pi - m) means θ + m < math.pi, so phi = cos(θ + m);\n",
    "            # else means θ + m >= math.pi, we use Talyer extension to approximate the cos(θ + m).\n",
    "            # if fact, cos(θ + m) = cos(θ) - m * sin(θ) >= cos(θ) - m * sin(math.pi - m)\n",
    "            phi = torch.where(cosine > self.threshold, phi, cosine - self.mm) # https://github.com/ronghuaiyang/arcface-pytorch/issues/48\n",
    "        # --------------------------- convert label to one-hot ---------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        # 对label形式进行onehot转换，假设batch为2、有3类的话，即将label从[1,2]转换成[[0,1,0],[0,0,1]]\n",
    "        one_hot = torch.zeros(cosine.size(), device=CONFIG['device'])\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        # label smoothing\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine) #验证是否匹配正确 \n",
    "        # 进行re-scale\n",
    "        output *= self.s\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0227c63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:10.515682Z",
     "iopub.status.busy": "2022-02-23T05:09:10.515050Z",
     "iopub.status.idle": "2022-02-23T05:09:16.208014Z",
     "shell.execute_reply": "2022-02-23T05:09:16.207079Z",
     "shell.execute_reply.started": "2022-02-23T04:59:57.485440Z"
    },
    "papermill": {
     "duration": 5.785999,
     "end_time": "2022-02-23T05:09:16.208162",
     "exception": false,
     "start_time": "2022-02-23T05:09:10.422163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class HappyWhaleModel(nn.Module):\n",
    "    def __init__(self, model_name, embedding_size, pretrained=True):\n",
    "        super(HappyWhaleModel, self).__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained) # 创建模型\n",
    "        # 获取 in_features，以及置空最后两层\n",
    "        if 'efficientnet' in model_name:\n",
    "            in_features = self.model.classifier.in_features\n",
    "            self.model.classifier = nn.Identity()\n",
    "            self.model.global_pool = nn.Identity()\n",
    "        elif 'nfnet' in model_name:\n",
    "            in_features = self.model.head.fc.in_features\n",
    "            self.model.head.fc = nn.Identity()\n",
    "            self.model.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling = GeM() # GeM Pooling\n",
    "        # bn层 + dense层\n",
    "        self.embedding = nn.Sequential(\n",
    "                            nn.BatchNorm1d(in_features),\n",
    "                            nn.Linear(in_features, embedding_size)\n",
    "                            )\n",
    "        # arcface\n",
    "        self.fc = ArcMarginProduct(embedding_size,  # in_features\n",
    "                                   CONFIG[\"num_classes\"], # out_features\n",
    "                                   s=CONFIG[\"s\"],  # scale\n",
    "                                   m=CONFIG[\"m\"],  # margin\n",
    "                                   easy_margin=CONFIG[\"easy_margin\"],  # easy_margin模式\n",
    "                                   ls_eps=CONFIG[\"ls_eps\"]) # label smoothing\n",
    "\n",
    "    def forward(self, images, labels):\n",
    "        '''\n",
    "        train/valid\n",
    "        '''\n",
    "        features = self.model(images) # backbone \n",
    "        pooled_features = self.pooling(features).flatten(1) # gem pooling\n",
    "        embedding = self.embedding(pooled_features) # embedding\n",
    "        output = self.fc(embedding, labels) # arcface\n",
    "        return output\n",
    "    \n",
    "    def extract(self, images):\n",
    "        '''\n",
    "        test\n",
    "        '''\n",
    "        features = self.model(images) # backbone \n",
    "        pooled_features = self.pooling(features).flatten(1) # gem pooling\n",
    "        embedding = self.embedding(pooled_features) # embedding\n",
    "        return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17cf96a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:16.382897Z",
     "iopub.status.busy": "2022-02-23T05:09:16.382016Z",
     "iopub.status.idle": "2022-02-23T05:09:16.384336Z",
     "shell.execute_reply": "2022-02-23T05:09:16.384757Z",
     "shell.execute_reply.started": "2022-02-23T05:00:02.291683Z"
    },
    "papermill": {
     "duration": 0.095398,
     "end_time": "2022-02-23T05:09:16.384911",
     "exception": false,
     "start_time": "2022-02-23T05:09:16.289513",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def get_embeddings(model, dataloader, device):\n",
    "    model.to(CONFIG['device'])\n",
    "    model.eval() # eval模式\n",
    "    \n",
    "    LABELS = []\n",
    "    EMBEDS = []\n",
    "    IDS = []\n",
    "    \n",
    "    bar = tqdm(enumerate(dataloader), total=len(dataloader)) # dataloader\n",
    "    for step, data in bar:        \n",
    "        images = data['image'].to(device, dtype=torch.float) # images to gpu\n",
    "        labels = data['label'].to(device, dtype=torch.long) # labels to gpu\n",
    "        ids = data['id'] # filename\n",
    "\n",
    "        outputs = model.extract(images) # 提取出 embedding\n",
    "        \n",
    "        LABELS.append(labels.cpu().numpy()) # labels存入list\n",
    "        EMBEDS.append(outputs.cpu().numpy())  # embedding存入list\n",
    "        IDS.append(ids) # filename 存入list\n",
    "    \n",
    "    EMBEDS = np.vstack(EMBEDS) # 合并 embedding\n",
    "    LABELS = np.concatenate(LABELS) # 合并 labels\n",
    "    IDS = np.concatenate(IDS) # 合并 filename\n",
    "    \n",
    "    return EMBEDS, LABELS, IDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1103ac6e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T05:09:16.570050Z",
     "iopub.status.busy": "2022-02-23T05:09:16.569386Z",
     "iopub.status.idle": "2022-02-23T05:09:16.572414Z",
     "shell.execute_reply": "2022-02-23T05:09:16.572850Z",
     "shell.execute_reply.started": "2022-02-23T05:00:02.302901Z"
    },
    "papermill": {
     "duration": 0.103684,
     "end_time": "2022-02-23T05:09:16.573006",
     "exception": false,
     "start_time": "2022-02-23T05:09:16.469322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(df, fold):\n",
    "    df_train = df[df.kfold != fold].reset_index(drop=True) # 切分训练集\n",
    "    df_valid = df[df.kfold == fold].reset_index(drop=True) # 切分验证集\n",
    "    \n",
    "    train_dataset = HappyWhaleDataset(df_train, transforms=data_transforms[\"train\"]) # 创建Train Datasets\n",
    "    valid_dataset = HappyWhaleDataset(df_valid, transforms=data_transforms[\"valid\"]) # 创建Valid Datasets\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CONFIG['train_batch_size'], num_workers=CONFIG[\"num_workers\"], shuffle=False, pin_memory=False) # Train DataLoader\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=CONFIG['valid_batch_size'], num_workers=CONFIG[\"num_workers\"], shuffle=False, pin_memory=False) # Valid DataLoader\n",
    "    \n",
    "    return train_loader, valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ccfe0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test df\n",
    "test_df = pd.DataFrame()\n",
    "test_df[\"image\"] = os.listdir(f\"{ROOT_DIR}/test_images\")\n",
    "test_df[\"file_path\"] = test_df[\"image\"].apply(lambda x: f\"{TEST_DIR}/{x}\")\n",
    "test_df[\"individual_id\"] = -1  #dummy value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d296252",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, valid_loader = prepare_loaders(df, fold=0) # train dataloader / valid dataloader\n",
    "test_dataset = HappyWhaleDataset(test_df, transforms=data_transforms[\"valid\"]) # test Dataset\n",
    "test_loader = DataLoader(test_dataset, batch_size=CONFIG['valid_batch_size'], num_workers=CONFIG[\"num_workers\"], shuffle=False, pin_memory=False) # test dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200cd3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 已训练完成的模型权重字典\n",
    "model_weight_dict = {\n",
    "    \"weights_dir\":[f\"{BASE_DIR}/tf_efficientnet_b6_ns_fold1.pth\",\n",
    "                   f\"{BASE_DIR}/tf_efficientnet_b6_ns_fold3.pth\",\n",
    "                   f\"{BASE_DIR}/tf_efficientnetv2_l_in21k_fold0.pth\",\n",
    "                   f\"{BASE_DIR}/tf_efficientnetv2_l_in21k_fold1.pth\",\n",
    "                   f\"{BASE_DIR}/tf_efficientnetv2_l_in21k_fold2.pth\",\n",
    "                   f\"{BASE_DIR}/tf_efficientnetv2_l_in21k_fold4.pth\",\n",
    "                   f\"{BASE_DIR}/eca_nfnet_l2_fold0.pth\",\n",
    "                   f\"{BASE_DIR}/eca_nfnet_l2_fold1.pth\",\n",
    "                   f\"{BASE_DIR}/eca_nfnet_l2_fold4.pth\",\n",
    "                   ],\n",
    "    \"model_name\": [\"tf_efficientnet_b6_ns\",\n",
    "                   \"tf_efficientnet_b6_ns\",\n",
    "                   \"tf_efficientnetv2_l_in21k\",\n",
    "                   \"tf_efficientnetv2_l_in21k\",\n",
    "                   \"tf_efficientnetv2_l_in21k\",\n",
    "                   \"tf_efficientnetv2_l_in21k\",\n",
    "                   \"eca_nfnet_l2\",\n",
    "                   \"eca_nfnet_l2\",\n",
    "                   \"eca_nfnet_l2\",\n",
    "                   ],\n",
    "    \"embedding_size\":[512, 512, 512, 512, 512, 512, 512, 512, 512],\n",
    "}\n",
    "\n",
    "train_embeds_list = []\n",
    "valid_embeds_list = []\n",
    "test_embeds_list = []\n",
    "train_labels_list = []\n",
    "valid_labels_list = []\n",
    "train_ids_list = []\n",
    "valid_ids_list = []\n",
    "test_ids_list = []\n",
    "\n",
    "for idx in range(len(model_weight_dict[\"weights_dir\"])):\n",
    "    weights_dir = model_weight_dict[\"weights_dir\"][idx] # weights_dir\n",
    "    model_name = model_weight_dict[\"model_name\"][idx] # model_name\n",
    "    embedding_size = model_weight_dict[\"embedding_size\"][idx] # embedding_size\n",
    "\n",
    "    model = HappyWhaleModel(model_name, embedding_size) # 创建 model\n",
    "    state = torch.load(weights_dir) # 读取权重文件\n",
    "\n",
    "    # weight to model\n",
    "    if CONFIG['gpu_parallel']:\n",
    "        new_state_dict = OrderedDict()\n",
    "        for k, v in state.items():\n",
    "            k=k[7:]\n",
    "            new_state_dict[k]=v\n",
    "        model.load_state_dict(new_state_dict)\n",
    "    else:\n",
    "        model.load_state_dict(state)\n",
    "    model.to(CONFIG['device']) # 模型存入GPU\n",
    "\n",
    "    train_embeds, train_labels, train_ids = get_embeddings(model, train_loader, CONFIG['device']) # 获取到 train 的 embedding, labels, IDS\n",
    "    valid_embeds, valid_labels, valid_ids = get_embeddings(model, valid_loader, CONFIG['device']) # 获取到 valid 的 embedding, labels, IDS\n",
    "    test_embeds, _, test_ids = get_embeddings(model, test_loader, CONFIG['device']) # 获取到 test 的 embedding, IDS\n",
    "\n",
    "    train_embeds_list.append(train_embeds)\n",
    "    valid_embeds_list.append(valid_embeds)\n",
    "    test_embeds_list.append(test_embeds)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    _ = gc.collect()\n",
    "\n",
    "train_embeds = np.concatenate(train_embeds_list,axis=1) # train_embeds\n",
    "valid_embeds = np.concatenate(valid_embeds_list,axis=1) # valid_embeds\n",
    "test_embeds = np.concatenate(test_embeds_list,axis=1) # test_embeds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c5dd3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors # knn\n",
    "neigh = NearestNeighbors(n_neighbors=CONFIG[\"KNN\"],metric='cosine') # 定义knn\n",
    "neigh.fit(train_embeds) # 训练knn\n",
    "valid_distances, valid_idxs = neigh.kneighbors(valid_embeds, CONFIG[\"KNN\"], return_distance=True) # 推理 knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd9b284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 逆标签编码\n",
    "train_allowed_labels = encoder.inverse_transform(train_labels) \n",
    "valid_allowed_labels = encoder.inverse_transform(valid_labels)\n",
    "\n",
    "train_allowed_labels_set = set(train_allowed_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a341c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置 new_individual\n",
    "val_targets_df = pd.DataFrame(np.stack([valid_ids, valid_allowed_labels], axis=1), columns=['image','target'])\n",
    "val_targets_df.loc[~val_targets_df.target.isin(train_allowed_labels_set),'target'] = 'new_individual' # valid中的individual若没有出现在train中，则设置为 new_individual\n",
    "val_targets_df.target.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b8e639",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = []\n",
    "for i in tqdm(range(len(valid_ids))):\n",
    "    id_ = valid_ids[i] # filename\n",
    "    targets = train_labels[valid_idxs[i]] # labels\n",
    "    distances = valid_distances[i] # distances\n",
    "    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n",
    "    subset_preds['image'] = id_\n",
    "    valid_df.append(subset_preds)\n",
    "valid_df = pd.concat(valid_df).reset_index(drop=True) \n",
    "valid_df['confidence'] = 1-valid_df['distances'] # 相似度\n",
    "valid_df = valid_df.groupby(['image','target']).confidence.max().reset_index() # 获取每张image最大的相似度\n",
    "valid_df = valid_df.sort_values('confidence',ascending=False).reset_index(drop=True) # 根据相似度排序\n",
    "valid_df['target'] = encoder.inverse_transform(valid_df['target'].astype(\"int\").to_list()) # 获取target原始名称\n",
    "valid_df.to_csv('val_neighbors.csv')\n",
    "valid_df.image.value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05879e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_list = ['938b7e931166', '5bf17305f073', '7593d2aee842', '7362d7a01d00','956562ff2888'] # 最常见的五个individual\n",
    "\n",
    "def get_predictions(test_df, threshold=0.2):\n",
    "    predictions = {} # 预测结果字典\n",
    "    for i, row in tqdm(test_df.iterrows()):\n",
    "        if row.image in predictions: # 若image以存在\n",
    "            if len(predictions[row.image]) == 5: # 如果正好为5个值，则跳过\n",
    "                continue\n",
    "            predictions[row.image].append(row.target) # 存下当前的target\n",
    "        elif row.confidence > threshold:\n",
    "            predictions[row.image] = [row.target, 'new_individual'] # 相似度大于new阈值，则[row.target, 'new_individual']\n",
    "        else:\n",
    "            predictions[row.image] = ['new_individual', row.target] # 反之，则['new_individual', row.target]\n",
    "\n",
    "    for x in tqdm(predictions):\n",
    "        if len(predictions[x]) < 5:\n",
    "            # 如果预测值小于5，则使用最常出现的5个样本代替\n",
    "            remaining = [y for y in sample_list if y not in predictions] # 获取代替样本\n",
    "            predictions[x] = predictions[x] + remaining # 加入代替样本\n",
    "            predictions[x] = predictions[x][:5] # 保留前五个值\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b542153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正式评价指标\n",
    "def map_per_image(label, predictions):\n",
    "    \"\"\"Computes the precision score of one image.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    label : string\n",
    "            The true label of the image\n",
    "    predictions : list\n",
    "            A list of predicted elements (order does matter, 5 predictions allowed per image)\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    score : double\n",
    "    \"\"\"    \n",
    "    try:\n",
    "        return 1 / (predictions[:5].index(label) + 1)\n",
    "    except ValueError:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5762fbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看不同knn相似度阈值下的cv分数\n",
    "best_th = 0  \n",
    "best_cv = 0\n",
    "for th in [0.1*x for x in range(11)]:  # [0.1,0.2,...,0.9,1.0]\n",
    "    print(\"threshold:\", th)\n",
    "    all_preds = get_predictions(valid_df,threshold=th) # 获取某个阈值下的预测结果\n",
    "    cv = 0\n",
    "    for i,row in val_targets_df.iterrows(): \n",
    "        target = row.target  # target\n",
    "        preds = all_preds[row.image]  # preds\n",
    "        val_targets_df.loc[i,th] = map_per_image(target,preds) # MAP score计算\n",
    "    cv = val_targets_df[th].mean() # cv平均值\n",
    "    print(f\"CV at threshold {th}: {cv}\")\n",
    "    if cv>best_cv:\n",
    "        best_th = th\n",
    "        best_cv = cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714ffbe8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:02:58.794305Z",
     "iopub.status.busy": "2022-02-23T06:02:58.793461Z",
     "iopub.status.idle": "2022-02-23T06:02:58.802367Z",
     "shell.execute_reply": "2022-02-23T06:02:58.801950Z",
     "shell.execute_reply.started": "2022-02-23T05:00:54.876684Z"
    },
    "papermill": {
     "duration": 0.336031,
     "end_time": "2022-02-23T06:02:58.802482",
     "exception": false,
     "start_time": "2022-02-23T06:02:58.466451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"Best threshold\", best_th)\n",
    "print(\"Best cv\",best_cv) \n",
    "val_targets_df.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e07716",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_targets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d802700a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adjustment: Since Public lb has nearly 10% 'new_individual' (Be Careful for private LB)\n",
    "val_targets_df['is_new_individual'] = val_targets_df.target=='new_individual' # 新建列'is_new_individual'，如果targe是new_individual\n",
    "print(val_targets_df.is_new_individual.value_counts().to_dict())  # 打印targets是或者不是new_individual的数值\n",
    "val_scores = val_targets_df.groupby('is_new_individual').mean().T # 每个阈值下，获取 new_individual 比例\n",
    "val_scores['adjusted_cv'] = val_scores[True]*0.15+val_scores[False]*0.85 # 根据比例调整cv分数\n",
    "best_threshold_adjusted = val_scores['adjusted_cv'].idxmax() # 获取新的best cv\n",
    "print(\"best_threshold\", best_threshold_adjusted)\n",
    "val_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade1da02",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da6e2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-23T06:08:30.698550Z",
     "iopub.status.busy": "2022-02-23T06:08:30.697347Z",
     "iopub.status.idle": "2022-02-23T06:08:30.738813Z",
     "shell.execute_reply": "2022-02-23T06:08:30.739504Z",
     "shell.execute_reply.started": "2022-02-23T05:00:55.684185Z"
    },
    "papermill": {
     "duration": 1.115278,
     "end_time": "2022-02-23T06:08:30.739714",
     "exception": false,
     "start_time": "2022-02-23T06:08:29.624436",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_embeds = np.concatenate([train_embeds, valid_embeds]) # 合并Train和Valid embeds\n",
    "all_labels = np.concatenate([train_labels, valid_labels]) # 合并Train和Valid labels\n",
    "print(all_embeds.shape, all_labels.shape)\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "neigh = NearestNeighbors(n_neighbors=CONFIG[\"KNN\"],metric='cosine') # 定义knn\n",
    "neigh.fit(all_embeds) # 训练 knn\n",
    "test_distances, test_idxs = neigh.kneighbors(test_embeds, CONFIG[\"KNN\"], return_distance=True) # 在test上推理knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0240bf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(f'{ROOT_DIR}/sample_submission.csv', index_col='image') # 读取 sample_submission.csv\n",
    "print(\"test_ids len:\",len(test_ids), \"sample_submission len:\",len(sample_submission))\n",
    "test_df = []\n",
    "for i in tqdm(range(len(test_ids))):  \n",
    "    id_ = test_ids[i]  # filename\n",
    "    targets = all_labels[test_idxs[i]]  # labels\n",
    "    distances = test_distances[i] # distances\n",
    "    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n",
    "    subset_preds['image'] = id_\n",
    "    test_df.append(subset_preds)\n",
    "test_df = pd.concat(test_df).reset_index(drop=True)\n",
    "test_df['confidence'] = 1-test_df['distances'] # 相似度\n",
    "test_df = test_df.groupby(['image','target']).confidence.max().reset_index() # 获取每张image最大的相似度\n",
    "test_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True) # 根据相似度排序\n",
    "test_df['target'] = encoder.inverse_transform(test_df['target'].astype(\"int\").to_list()) # 获取target原始名称\n",
    "test_df.to_csv('test_neighbors.csv')\n",
    "test_df.image.value_counts().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c5644a",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = {} # 预测结果字典\n",
    "for i,row in tqdm(test_df.iterrows()):\n",
    "    if row.image in predictions: # 若image以存在\n",
    "        if len(predictions[row.image])==5: # 如果正好为5个值，则跳过\n",
    "            continue\n",
    "        predictions[row.image].append(row.target) # 存下当前的target\n",
    "    elif row.confidence>best_threshold_adjusted:\n",
    "        predictions[row.image] = [row.target,'new_individual'] # 相似度大于new阈值，则[row.target, 'new_individual']\n",
    "    else:\n",
    "        predictions[row.image] = ['new_individual',row.target] # 反之，则['new_individual', row.target]\n",
    "        \n",
    "for x in tqdm(predictions):\n",
    "    if len(predictions[x])<5:\n",
    "        # 如果预测值小于5，则使用最常出现的5个样本代替\n",
    "        remaining = [y for y in sample_list if y not in predictions] # 获取代替样本\n",
    "        predictions[x] = predictions[x]+remaining # 加入代替样本\n",
    "        predictions[x] = predictions[x][:5] # 保留前五个值\n",
    "    predictions[x] = ' '.join(predictions[x])\n",
    "    \n",
    "# 输出 submission.csv\n",
    "predictions = pd.Series(predictions).reset_index()\n",
    "predictions.columns = ['image','predictions']\n",
    "predictions.to_csv('submission.csv',index=False)\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12a1056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 5600.769643,
   "end_time": "2022-02-23T06:41:50.944700",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-02-23T05:08:30.175057",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
